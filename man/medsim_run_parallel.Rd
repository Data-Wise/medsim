% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/parallel.R
\name{medsim_run_parallel}
\alias{medsim_run_parallel}
\title{Run Tasks in Parallel}
\usage{
medsim_run_parallel(
  tasks,
  fun,
  n_cores = NULL,
  progress = TRUE,
  export = NULL,
  packages = NULL,
  cluster_type = NULL
)
}
\arguments{
\item{tasks}{Vector or list: Tasks to process (e.g., 1:100, list of params)}

\item{fun}{Function: Function to apply to each task. Should accept one
argument (the task) and return a result.}

\item{n_cores}{Integer: Number of CPU cores to use. If NULL, uses all
available cores minus 2.}

\item{progress}{Logical: Show progress bar (default TRUE). Automatically
suppressed when running on cluster (batch jobs).}

\item{export}{Character vector: Names of objects to export to workers.
These objects must be available in the calling environment.}

\item{packages}{Character vector: Names of packages to load on each worker.
Use this if \code{fun} requires specific packages.}

\item{cluster_type}{Character: Type of cluster ("PSOCK" or "FORK"). FORK
is more efficient but only works on Unix. Auto-detected by default.}
}
\value{
List: Results from applying \code{fun} to each task (same length as tasks)
}
\description{
Executes a list of tasks in parallel using multiple CPU cores. Provides
progress bars, proper error handling, and automatic cluster management.
}
\details{
\subsection{Cluster Types}{
\itemize{
\item \strong{PSOCK} (default on Windows): Creates separate R sessions. Requires
explicit export of objects and packages. Works on all platforms.
\item \strong{FORK} (default on Unix): Copies current R session. More efficient,
automatic object sharing, but Unix-only.
}
}

\subsection{Progress Bars}{

Progress bars are shown in interactive sessions and local execution, but
suppressed on HPC clusters to avoid cluttering log files.
}

\subsection{Error Handling}{

If a task fails:
\itemize{
\item Error is caught and returned as an error object
\item Other tasks continue processing
\item Check results with \code{sapply(results, inherits, "error")}
}
}

\subsection{Memory Considerations}{

Each worker process requires memory. For large tasks:
\itemize{
\item Reduce \code{n_cores} if running out of memory
\item Process tasks in chunks
\item Use FORK cluster (Unix) which shares memory
}
}
}
\examples{
\dontrun{
# Simple parallel computation
results <- medsim_run_parallel(
  tasks = 1:100,
  fun = function(i) {
    Sys.sleep(0.1)  # Simulate work
    i^2
  },
  n_cores = 4
)

# With exports
my_data <- data.frame(x = 1:10, y = 11:20)

results <- medsim_run_parallel(
  tasks = 1:10,
  fun = function(i) {
    mean(my_data$x[1:i])
  },
  export = "my_data"
)

# With packages
results <- medsim_run_parallel(
  tasks = 1:10,
  fun = function(i) {
    dplyr::tibble(x = i, y = i^2)
  },
  packages = "dplyr"
)

# Check for errors
errors <- sapply(results, inherits, "error")
if (any(errors)) {
  cat("Errors occurred in:", which(errors), "\n")
}
}

}
\seealso{
\code{\link[parallel:makeCluster]{parallel::makeCluster()}}, \code{\link[parallel:clusterApply]{parallel::parLapply()}}, \code{\link[pbapply:pbapply]{pbapply::pblapply()}}
}
